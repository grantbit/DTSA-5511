{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Monet Painting","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nimport numpy as np\nimport torch\nfrom torch import nn, Tensor\nfrom torchvision.utils import save_image\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport zipfile\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T23:41:31.789642Z","iopub.execute_input":"2024-08-08T23:41:31.790232Z","iopub.status.idle":"2024-08-08T23:41:31.796562Z","shell.execute_reply.started":"2024-08-08T23:41:31.790198Z","shell.execute_reply":"2024-08-08T23:41:31.795306Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# Define the directories for Monet and photo images\nmonet_images_dir = '/kaggle/input/gan-getting-started/monet_jpg'\nphoto_images_dir = '/kaggle/input/gan-getting-started/photo_jpg'\n\n# Create new directories for renamed images\nnew_monet_dir = 'monet_jpg'\nnew_photo_dir = 'photo_jpg'\n\nos.makedirs(new_monet_dir, exist_ok=True)\nos.makedirs(new_photo_dir, exist_ok=True)\n\n# Function to change file names\ndef change_file_name(folder_dir, new_folder_dir):\n    files = os.listdir(folder_dir)\n    for index, filename in enumerate(files):\n        old_filename = os.path.join(folder_dir, filename)\n        new_filename = os.path.join(new_folder_dir, f'{index}.jpg')\n        shutil.copyfile(old_filename, new_filename)\n\n# Change file names for Monet and photo images\nchange_file_name(monet_images_dir, new_monet_dir)\nchange_file_name(photo_images_dir, new_photo_dir)\n\n# Define the main dataset directory\ndataset_dir = 'dataset'\n\n# Create train and test directories\ntrain_dir = os.path.join(dataset_dir, 'train')\ntest_dir = os.path.join(dataset_dir, 'test')\n\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)\n\ndef split_data(source_dir, train_dir, test_dir, train_ratio=0.8):\n    # Ensure destination directories exist\n    os.makedirs(train_dir, exist_ok=True)\n    os.makedirs(test_dir, exist_ok=True)\n\n    # List all files in the source directory\n    files = os.listdir(source_dir)\n    # Shuffle the files to ensure random distribution\n    random.shuffle(files)\n\n    # Calculate the split index\n    split_index = int(len(files) * train_ratio)\n\n    # Split the files into train and test sets\n    train_files = files[:split_index]\n    test_files = files[split_index:]\n\n    # Move files to the training directory\n    for file_name in train_files:\n        src_file = os.path.join(source_dir, file_name)\n        dst_file = os.path.join(train_dir, file_name)\n        shutil.move(src_file, dst_file)\n\n    for file_name in test_files:\n        src_file = os.path.join(source_dir, file_name)\n        dst_file = os.path.join(test_dir, file_name)\n        shutil.move(src_file, dst_file)\n\n# Monet\nsource_monet_dir = 'monet_jpg'\ntrain_monet_dir = os.path.join(train_dir, 'monet')\ntest_monet_dir = os.path.join(test_dir, 'monet')\nsplit_data(source_monet_dir, train_monet_dir, test_monet_dir)\n\n# Photo\nsource_photo_dir = 'photo_jpg'\ntrain_photo_dir = os.path.join(train_dir, 'photo')\ntest_photo_dir = os.path.join(test_dir, 'photo')\nsplit_data(source_photo_dir, train_photo_dir, test_photo_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T23:41:31.799232Z","iopub.execute_input":"2024-08-08T23:41:31.799693Z","iopub.status.idle":"2024-08-08T23:41:40.138738Z","shell.execute_reply.started":"2024-08-08T23:41:31.799653Z","shell.execute_reply":"2024-08-08T23:41:40.137685Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# Define the generator\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        return self.main(input)\n\n# Define the discriminator\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.main(input)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T23:41:40.140186Z","iopub.execute_input":"2024-08-08T23:41:40.140644Z","iopub.status.idle":"2024-08-08T23:41:40.154661Z","shell.execute_reply.started":"2024-08-08T23:41:40.140604Z","shell.execute_reply":"2024-08-08T23:41:40.153372Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# Create the generator\nnetG = Generator().to(device)\n\n# Create the discriminator\nnetD = Discriminator().to(device)\n\n# Initialize BCELoss function\ncriterion = nn.BCELoss()\n\n# Create batch of latent vectors that we will use to visualize the progression of the generator\nfixed_noise = torch.randn(64, 100, 1, 1, device=device)\n\n# Establish convention for real and fake labels during training\nreal_label = 1\nfake_label = 0\n\n# Setup Adam optimizers for both G and D\noptimizerD = torch.optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizerG = torch.optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T23:41:40.156023Z","iopub.execute_input":"2024-08-08T23:41:40.156422Z","iopub.status.idle":"2024-08-08T23:41:40.238460Z","shell.execute_reply.started":"2024-08-08T23:41:40.156387Z","shell.execute_reply":"2024-08-08T23:41:40.237341Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# Ensure the output directory exists\noutput_dir = 'output'\nos.makedirs(output_dir, exist_ok=True)\n\n# Image transformations\ntransform = transforms.Compose([\n    transforms.Resize(256),  # Change to 256x256\n    transforms.CenterCrop(256),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Load the dataset\ndataset = ImageFolder(root='dataset/train', transform=transform)\ndataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n\n# Training Loop\nnum_epochs = 1\n\nfor epoch in range(num_epochs):\n    for i, data in enumerate(dataloader, 0):\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ## Train with all-real batch\n        netD.zero_grad()\n        real_cpu = data[0].to(device)\n        b_size = real_cpu.size(0)\n        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n        output = netD(real_cpu).view(-1)\n        output = output[:b_size]  \n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        ## Train with all-fake batch\n        noise = torch.randn(b_size, 100, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach()).view(-1)\n        output = output[:b_size]  \n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        # (2) Update G network: maximize log(D(G(z)))\n        netG.zero_grad()\n        label.fill_(real_label)  \n        output = netD(fake).view(-1)\n        output = output[:b_size]  \n        errG = criterion(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        # Output training stats\n        if i % 50 == 0:\n            print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}] '\n                  f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n                  f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n\n        # Save images every 500 steps\n        if i % 500 == 0:\n            with torch.no_grad():\n                fake = netG(fixed_noise).detach().cpu()\n            save_image(fake, f'{output_dir}/fake_samples_epoch_{epoch}_{i}.png', normalize=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T23:41:40.240931Z","iopub.execute_input":"2024-08-08T23:41:40.241319Z","iopub.status.idle":"2024-08-08T23:58:38.167251Z","shell.execute_reply.started":"2024-08-08T23:41:40.241287Z","shell.execute_reply":"2024-08-08T23:58:38.165869Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"[0/1][0/58] Loss_D: 1.2740 Loss_G: 3.1712 D(x): 0.5386 D(G(z)): 0.4665 / 0.0437\n[0/1][50/58] Loss_D: 0.0471 Loss_G: 6.0908 D(x): 0.9704 D(G(z)): 0.0166 / 0.0025\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport zipfile\n\n# Ensure the output directory exists\noutput_dir = '/kaggle/working/output'\nos.makedirs(output_dir, exist_ok=True)\n\n# Number of images to generate\nnum_images_to_generate = 7000\noutput_zip = '/kaggle/working/images.zip'\n\n# Generate images and save them to the output directory and zip file\nwith zipfile.ZipFile(output_zip, 'w') as zipf:\n    for i in range(num_images_to_generate):\n        noise = torch.randn(1, 100, 1, 1, device=device)\n        with torch.no_grad():\n            fake_image = netG(noise).detach().cpu()\n        # Transform back to PIL image\n        fake_image_pil = transforms.ToPILImage()(fake_image.squeeze())\n        # Save the image to the output directory\n        image_path = os.path.join(output_dir, f'image_{i}.jpg')\n        fake_image_pil.save(image_path)\n        # Add the image to the zip file\n        zipf.write(image_path, arcname=f'image_{i}.jpg')\n\nprint(\"Image generation and zipping complete. Images are saved in the /kaggle/working/output directory.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T00:04:14.142648Z","iopub.execute_input":"2024-08-09T00:04:14.143078Z","iopub.status.idle":"2024-08-09T00:05:04.763808Z","shell.execute_reply.started":"2024-08-09T00:04:14.143045Z","shell.execute_reply":"2024-08-09T00:05:04.762517Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Image generation and zipping complete. Images are saved in the /kaggle/working/output directory.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Conclusion:\nDuring the training of the GAN model, we observed significant improvements in both the generator and discriminator as they learned to perform their tasks more effectively. Initially, the discriminator struggled to differentiate between real and fake images, with a loss of 1.2740, while the generator faced challenges in creating convincing images, reflected by its loss of 3.1712. As the training progressed, the discriminator became much better at identifying real versus generated images, with its loss dropping to just 0.0471. At the same time, the generator improved its ability to create realistic images, bringing its loss down to 6.0908. The discriminator's accuracy in recognizing real images increased from 53.86% to 97.04%, and its ability to detect fake images also improved significantly. These changes indicate that within just a single epoch, the model made considerable strides in its performance, with both networks effectively learning from each other.","metadata":{}}]}